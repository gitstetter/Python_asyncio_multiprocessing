{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "CPython -common implementation we all use-  does not use multiple CPUs by default.\n",
    "\n",
    "Expect *±n-times* speed-up of execution time with *n cores*.\n",
    "\n",
    "Each additional process will increase communication overhead and decrease available RAM up to a significant overall slowdown.\n",
    "\n",
    "Amdahls law: *If only a small part of your code can be parallelized, it doesn't matter how many CPUs you use - it won't run much faster after all*\n",
    "\n",
    "If each process needs to communicate with every other Python process, the communication overhead will slowly overwhelm the processing and slow things down.\n",
    "\n",
    "As more and more processes are added, overalle performance can be slowed down.\n",
    "\n",
    "Typlical jobs for multiprocessing module:\n",
    "* Parallelize a CPU-bound task with Process or Pool bjects\n",
    "* Parallelize a IO-bound task in a Pool with threads (dummy module)\n",
    "* Share pickled work via a Queue\n",
    "* Share state between parallelized workers (bytes, primitive datatypes, dicts, lists)\n",
    "\n",
    "**Threads** in Python are bound by the GIL (Global Interpreter Lock), so only one thread may interact with Python projects at a time.\n",
    "\n",
    "By using **processes**, we run a number of Python interpreters in parallel - each with a private memory space with its own GIL -and each running in series -> no competition for each GIL."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiprocessing module\n",
    "\n",
    "Main components:\n",
    "* **Process**: \n",
    "forked copy of current process (new pid - independent child process in operating system - provide it with target method to run)\n",
    "* **Pool**:\n",
    "wraps the process/threading - Thread API into a convenient pool of workers that share chunk of work und return aggregated result\n",
    "* **Queue**:\n",
    "FIFO queue allowing multiple producers and consumers\n",
    "* **Pipe**:\n",
    "Uni-/bidirectional communication cannel between two processes\n",
    "* **Manager**:\n",
    "High level managed interface to share Python objects between processes\n",
    "* **ctypes**:\n",
    "Allows sharing of primitive datatypes (ints flaots, bytes) between processes after they have forked\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using prosesses\n",
    "\n",
    "The Pool.apply and Pool.map methods are basically equivalents to Python’s in-built apply and map functions. \n",
    "\n",
    "The Pool.map and Pool.apply will lock the main program until all processes are finished, which is quite useful if we want to obtain results in a particular order for certain applications.\n",
    "\n",
    "#### pool.map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cube(x):\n",
    "    return x**3\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    from multiprocessing import Pool #<- multiprocessing to set up a pool of processes -> multiple pid\n",
    "\n",
    "    pool = Pool(processes=4)\n",
    "\n",
    "    results = pool.map(cube, range(1,7))\n",
    "\n",
    "    print(results)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pool.apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cube(x):\n",
    "    return x**3\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    from multiprocessing import Pool #<- multiprocessing to set up a pool of processes -> multiple pid\n",
    "\n",
    "    pool = Pool(processes=4)\n",
    "\n",
    "    results = [pool.apply(cube, args=(x,)) for x in range(1,7)]\n",
    "    print(results)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using threads\n",
    "\n",
    "Instead of importing multiprocessing import **multiprocessing.dummy**\n",
    "\n",
    "#### dummy.pool.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cube(x):\n",
    "    return x**3\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    from multiprocessing.dummy import Pool #<- multiprocessing.dummy to set up a pool of threads -> same pid\n",
    "\n",
    "    pool = Pool(processes=4)\n",
    "\n",
    "    results = [pool.apply(cube, args=(x,)) for x in range(1,7)]\n",
    "\n",
    "    print(results)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dummy.pool.map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cube(x):\n",
    "    return x**3\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    from multiprocessing.dummy import Pool #<- multiprocessing.dummy to set up a pool of threads -> same pid\n",
    "\n",
    "    pool = Pool(processes=4)\n",
    "\n",
    "    results = pool.map(cube, range(1,7))\n",
    "\n",
    "    print(results)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joblib module\n",
    "https://joblib.readthedocs.io/en/latest/parallel.html\n",
    "\n",
    "Joblib is an improvement on multiprocesing module:\n",
    "\n",
    "- easy parallel computing\n",
    "\n",
    "- transparent disk-based caching of results\n",
    "\n",
    "- focus on numpy arrays\n",
    "\n",
    "For parallel computing we need the Parallel Class and delayed decorator:\n",
    "\n",
    "- Paralllel sets up a process pool\n",
    "- delayed wraps target function to be applied to instantiated parallel object via an iterator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "\n",
    "def cube(x):\n",
    "    return x**3\n",
    "\n",
    "results = Parallel(n_jobs= 4, verbose=1)\\\n",
    "        (delayed(cube)\\\n",
    "        (x) for x in range(7))\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joblib mempory cache\n",
    "\n",
    "Memory cache: decorator that places function results based on input arguments to a disc cache -> persists between Python sessions. \n",
    "\n",
    "Refresh only when cache location is cleared or decorated function is changed - not any subfunctions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed, Memory\n",
    "\n",
    "memory = Memory(\"./joblib_cache\", verbose=0) #Set location of cache\n",
    "\n",
    "@memory.cache # Place decorator to cached function\n",
    "def cube(x):\n",
    "    return x**3\n",
    "\n",
    "results = Parallel(n_jobs= 4)\\\n",
    "        (delayed(cube)\\\n",
    "        (x) for x in range(7))\n",
    "\n",
    "print(results)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7baa7dfc784b53c35741efd030a93ab8ffd7dc95878d4ff67192074702ba81a8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
