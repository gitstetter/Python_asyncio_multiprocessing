{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "Getting the relevant data to code basis can be the bottleneck, as opposed to the actual code itself.\n",
    "\n",
    "When this is the case, the program is calles I/O bound -> the speed is bounded by the efficiency of the input/output\n",
    "\n",
    "Every time code reads from a file or writes to a network socket, it must pause to contact the kernel, request that the actual read happens, and then wait for it to complete.\n",
    "\n",
    "This is because it's not the program but the kernel that does the actual read operation, as the kernel is responsible for managing any interaction with the hardware.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most I/O operations on devices are multiple times slower than the CPU. So even if the communication with the kernel is fast, most time is spent for the kernel to get the result from the device and send it back to the program.\n",
    "\n",
    "During this time the propram is halted, until it gets a signal that the write operation has completed. Time spent in a paused state is called I/O wait"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asynchronous I/O helps to utilize this waiting time by allowing  to perform other operations while the program is in I/O state:\n",
    "\n",
    "![](./pics/IMG_6462.jpg)\n",
    "\n",
    "\n",
    "This is possible because while a program is in I/O wait, the kernel is simply waiting for the device requested to read from to send a signal that the requested data is ready.\n",
    "\n",
    "\n",
    "Instead of waiting, we can create a mechanism (event loop) so that we can dispatch requests of data, continue performing compute operations, and be notified when the data is ready to be read."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important: this is all still happening an a single thread and still uses one CPU at a time**\n",
    "\n",
    "In contrast to multiprocessing/multithreading, where a new process is launched that does experience I/O wait but uses multitasking nature of modern CPUs to allow the main process to continue.\n",
    "\n",
    "These two mechanisms are often used in tandem: multiple processes are launched, each is efficient at asynchronous I/O.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When a programm enters I/O wait, the execution is paused so that the kernel can perform low-level operations associated with I/O request (context switch), and it is not resumed until I/O operation is completed.\n",
    "\n",
    "Context switch is a heavy operation as it requires to save the state of the program and give up the use of the CPU.\n",
    "\n",
    "Later the program needs to be reinitialized and resumed.\n",
    "\n",
    "With concurrency a event loop is running that manages what gets to run in the program and when.\n",
    "\n",
    "*Event loop = list of functions that need to be run*\n",
    "\n",
    "![](./pics/event-loop.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n",
      "world\n",
      "Hello\n",
      "world\n"
     ]
    }
   ],
   "source": [
    "from queue import Queue\n",
    "from functools import partial\n",
    "from time import sleep\n",
    "\n",
    "eventloop = None\n",
    "\n",
    "class EventLoop(Queue):\n",
    "    def start(self):\n",
    "        for i in range(4):\n",
    "            function = self.get()\n",
    "            function()\n",
    "\n",
    "def do_hello():\n",
    "    global eventloop\n",
    "    print(\"Hello\")\n",
    "    sleep(1)\n",
    "    eventloop.put(do_world)\n",
    "\n",
    "def do_world():\n",
    "    global eventloop\n",
    "    print(\"world\")\n",
    "    sleep(1)\n",
    "    eventloop.put(do_hello)\n",
    "\n",
    "eventloop = EventLoop()\n",
    "eventloop.put(do_hello)\n",
    "eventloop.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The eventloop.put(do_world) approximates an asynchronous call to the do_world function.\n",
    "\n",
    "This operation is called **nonblocking**  -> it will return immediately but guarantee that do_world is called at some point later.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How does async/await work?\n",
    "\n",
    "An async function (assigned with **async def**) is called coroutine and is comparable to a generator.\n",
    "\n",
    "An **await** statement is similar in function to a yield statement: the execution of the current function gets paused while other code is run.\n",
    "\n",
    "Once the await / yield resolves with data, the function is resumed. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## General syntax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "async def hello(): # <-Define coroutine with async\n",
    "    print('Hello world!')\n",
    "    await asyncio.sleep(1) # <- await execution of nunblocking function/coroutine\n",
    "    return 'Hello again!' # <- return statement after stuff is awaited\n",
    "\n",
    "\n",
    "#asyncio.run(hello()) # <- start the event loop and run the coroutine.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A coroutine (**async def**) must always: \n",
    "- be **await**ed, \n",
    "- executed with **asyncio.run()**, \n",
    "- scheduled with **asyncio.create_task()** or \n",
    "- gathered with **asyncio.gather()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import time\n",
    "\n",
    "async def say_something(delay, words): #<- define coroutine\n",
    "    print(f\"Before {words}\")\n",
    "    await asyncio.sleep(delay)  #<- await nonblocking function/coroutine\n",
    "    print(f\"After {words}\")\n",
    "\n",
    "async def main():\n",
    "    print(f\"Started: {time.strftime('%X')}\")\n",
    "    task1 = asyncio.create_task(say_something(1, \"Task 1\")) #<- Create concurrent tasks independent from each other\n",
    "    task2 = asyncio.create_task(say_something(2, \"Task 2\")) #<- Create concurrent tasks independent from each other\n",
    "    await task1 #<- wait for task to finish\n",
    "    await task2 #<- wait for task to finish\n",
    "    print(f\"Finished: {time.strftime('%X')}\")\n",
    "# asyncio.run(main())   #<- Run everything concurrently"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**asyncio.gather()** takes coroutines as arguments and runs them concurrently \n",
    "\n",
    "-> no need to define and await each task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import time\n",
    "\n",
    "async def greetings():  #<- define coroutine\n",
    "    print(\"Welcome\")\n",
    "    await asyncio.sleep(1)  #<- await nonblocking function/coroutine\n",
    "    print(\"Goodbye\")\n",
    "\n",
    "async def main():\n",
    "    start = time.time()\n",
    "    await asyncio.gather(greetings(), greetings()) #<- Await & Create multiple concurrent tasks\n",
    "    elapsed = time.time() - start\n",
    "    print(f\"{__name__} executed in {elapsed:0.2f} seconds.\")\n",
    "\n",
    "#asyncio.run(main())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Awaitable objects\n",
    "\n",
    "An object is called awaitable if it can be used with the await keyword:\n",
    "- coroutines\n",
    "\n",
    "    **await asyncio.sleep(delay)**\n",
    "- tasks\n",
    "\n",
    "    task2 = asyncio.create_task(say_something(2, \"Task 2\"))\n",
    "    \n",
    "    **await task1**\n",
    "- futures\n",
    "\n",
    "    A Future is a low-level awaitable object that represents the result of an asynchronous computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "from asyncio import Future\n",
    "future = Future()\n",
    "print(future.done())\n",
    "print(future.cancelled())\n",
    "future.cancel()\n",
    "print(future.done())\n",
    "print(future.cancelled())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sephamores\n",
    "\n",
    "A sephamore works by making sure that only a certain number of coroutines can enter the context block at a time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import aiohttp\n",
    "\n",
    "\n",
    "def chunked_http_client(num_chunks):\n",
    "    \"\"\"\n",
    "    Returns a function that can fetch from a URL, ensuring that only\n",
    "    \"num_chunks\" of simultaneous connects are made.\n",
    "    \"\"\"\n",
    "    semaphore = asyncio.Semaphore(num_chunks)  # <- define limit of requests\n",
    "\n",
    "    async def http_get(url, client_session):  # <- new coroutine to download files files asynchonously using semaphore\n",
    "        nonlocal semaphore #<- nonlocal keyword is used to work with variables inside nested functions, where the variable should not belong to the inner function.\n",
    "        async with semaphore:\n",
    "            async with client_session.request(\"GET\", url) as response:\n",
    "                return await response.content.read() #<- return futures\n",
    "\n",
    "    return http_get\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "async def run():\n",
    "    urls = [\"https://binaryjazz.us/wp-json/genrenator/v1/genre/\"]*1000 #<- input lists to get from\n",
    "    responses = [] #<- putput list of http responses\n",
    "\n",
    "    http_client = chunked_http_client(100) #<- set async http client wit limit of parallel requests\n",
    "\n",
    "    async with aiohttp.ClientSession() as client_session: #<- use aiohttp.ClientSession to call nonblocking get function in http_get()\n",
    "        tasks = [http_client(url, client_session) for url in urls]  # save returned futures as list\n",
    "        for future in asyncio.as_completed(tasks):  # wait for futures to complete\n",
    "            data = await future\n",
    "            responses.append(data)\n",
    "    print(len(responses))\n",
    "    return responses\n",
    "\n",
    "if __name__ ==\"__main__\":\n",
    "    loop = asyncio.get_event_loop()\n",
    "    responses = loop.run_until_complete(run())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timeouts\n",
    "\n",
    "asyncio.wait_for(awaitable, timeout, *) to set a timeout for an awaitable object to complete.\n",
    "\n",
    "Use it to raise an exception if the awaitable object takes too long to complete. The exception as asyncio.TimeoutError."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "async def slow_operation():\n",
    "    await asyncio.sleep(400) #<- too long for timeout\n",
    "    print(\"Completed.\")\n",
    "\n",
    "async def main():\n",
    "    try:\n",
    "        await asyncio.wait_for(slow_operation(), timeout=1.0)\n",
    "    except asyncio.TimeoutError:\n",
    "        print(\"Timed out!\")\n",
    "#asyncio.run(main())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Links\n",
    "https://testdriven.io/blog/concurrency-parallelism-asyncio/#asyncio\n",
    "\n",
    "https://www.integralist.co.uk/posts/python-asyncio/\n",
    "\n",
    "\n",
    "https://medium.com/the-brainwave/intro-to-asynchronous-programming-in-python-with-async-io-7cb4717cd91d\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7baa7dfc784b53c35741efd030a93ab8ffd7dc95878d4ff67192074702ba81a8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
